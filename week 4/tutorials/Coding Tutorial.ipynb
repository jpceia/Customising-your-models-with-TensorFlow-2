{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        # self.dropout = Dropout(0.4)\n",
    "        self.dense_3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs): #, training=True):\n",
    "        x = self.dense_1(inputs)\n",
    "        # if training:\n",
    "        #    x = self.dropout(x)\n",
    "        y1 = self.dense_2(inputs)\n",
    "        y2 = self.dense_3(y1)\n",
    "        concat = concatenate([x, y2])\n",
    "        return self.softmax(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  704       \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  55        \n",
      "                                                                 \n",
      " softmax (Softmax)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1, 10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.02204629 0.01787825 0.04503302]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[-0.00268521,  0.03462158, -0.0207774 ],\n",
      "       [ 0.09371381, -0.06237426, -0.02519549],\n",
      "       [-0.04206321,  0.00716243,  0.02584009],\n",
      "       [-0.00878073,  0.01470047,  0.01333892],\n",
      "       [-0.01813836,  0.02376802,  0.0518269 ]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units, ),\n",
    "                                initializer='zeros')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)\n",
    "x = tf.ones((1, 5))\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal',\n",
    "                                trainable=False)\n",
    "        self.b = self.add_weight(shape=(units, ),\n",
    "                                initializer='zeros',\n",
    "                                trainable=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 0\n",
      "non-trainable weights: 2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units, ),\n",
    "                                initializer='zeros')\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units, )),\n",
    "                                         trainable=False)\n",
    "        self.number_call = tf.Variable(initial_value=0,\n",
    "                                        trainable=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer = MyLayerMean(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03485269  0.05023829  0.07178591]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00760896 0.02016134 0.00098963 0.01273838 0.00136442 0.0288148\n",
      "  0.00458228 0.00269921 0.02561857 0.04228117 0.03111967 0.00680765\n",
      "  0.00849164 0.01718308 0.00563838 0.04040192 0.02159702 0.00903688\n",
      "  0.02053146 0.00570727 0.00680501 0.00851963 0.01046056 0.03321978\n",
      "  0.00271517 0.0024523  0.01190842 0.00439264 0.16449364 0.0052294\n",
      "  0.0502124  0.00181331 0.0206602  0.02481423 0.00713237 0.04306683\n",
      "  0.05625549 0.01189698 0.00463357 0.00435206 0.030661   0.02276418\n",
      "  0.0234392  0.03887222 0.07332797 0.02252782]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_layer_2 (MyLayer)        multiple                  640064    \n",
      "                                                                 \n",
      " my_dropout (MyDropout)      multiple                  0         \n",
      "                                                                 \n",
      " my_layer_3 (MyLayer)        multiple                  4160      \n",
      "                                                                 \n",
      " my_dropout_1 (MyDropout)    multiple                  0         \n",
      "                                                                 \n",
      " my_layer_4 (MyLayer)        multiple                  2990      \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 0\n",
      "Non-trainable params: 647,214\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22cf8154430>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.03762624 -0.0384219  -0.00289748 -0.01989319 -0.04010193 -0.00090029\n",
      " -0.01950653 -0.02581614 -0.03236592 -0.03642849 -0.03013036 -0.01600526\n",
      " -0.04256559 -0.02685132 -0.03305507 -0.02598624 -0.00165259 -0.00075177\n",
      " -0.02645922 -0.01689888], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape = (1, ),\n",
    "                                 initializer='random_normal')\n",
    "        self.b = self.add_weight(shape = (1, ),\n",
    "                                 initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.m * inputs + self.b\n",
    "    \n",
    "linear_regression = LinearLayer()\n",
    "\n",
    "print(linear_regression(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.521688\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss 6.521688\n",
      "Step 1, Loss 4.957906\n",
      "Step 2, Loss 3.769851\n",
      "Step 3, Loss 2.867247\n",
      "Step 4, Loss 2.181508\n",
      "Step 5, Loss 1.660527\n",
      "Step 6, Loss 1.264718\n",
      "Step 7, Loss 0.964006\n",
      "Step 8, Loss 0.735541\n",
      "Step 9, Loss 0.561965\n",
      "Step 10, Loss 0.430090\n",
      "Step 11, Loss 0.329895\n",
      "Step 12, Loss 0.253770\n",
      "Step 13, Loss 0.195931\n",
      "Step 14, Loss 0.151985\n",
      "Step 15, Loss 0.118593\n",
      "Step 16, Loss 0.093220\n",
      "Step 17, Loss 0.073939\n",
      "Step 18, Loss 0.059286\n",
      "Step 19, Loss 0.048150\n",
      "Step 20, Loss 0.039685\n",
      "Step 21, Loss 0.033250\n",
      "Step 22, Loss 0.028357\n",
      "Step 23, Loss 0.024635\n",
      "Step 24, Loss 0.021804\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    \n",
    "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[0.98337346]\n",
      "b:2,  trained b:[1.9207152]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22cfa1c7130>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                initializer='random_normal',\n",
    "                                name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units, ),\n",
    "                                initializer='zeros',\n",
    "                                name='bias')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)\n",
    "\n",
    "    \n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.layer_1 = MyLayer(units_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        \n",
    "        return self.softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01497494 0.03043455 0.01918042 0.02761771 0.01596452 0.03523653\n",
      "  0.02876543 0.02418777 0.01468436 0.02534488 0.02163824 0.01323018\n",
      "  0.0136885  0.01481723 0.03021872 0.01772157 0.01097989 0.01147461\n",
      "  0.01935245 0.02591318 0.02484052 0.02718798 0.01487327 0.01938962\n",
      "  0.02390227 0.02309306 0.02944417 0.01969609 0.00766566 0.02911266\n",
      "  0.02390557 0.02656691 0.03126537 0.01378215 0.02012121 0.02180925\n",
      "  0.02226049 0.01711592 0.01326978 0.02485401 0.02125877 0.02609047\n",
      "  0.01943485 0.02735299 0.03465132 0.02162999]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_layer_5 (MyLayer)        multiple                  640064    \n",
      "                                                                 \n",
      " my_dropout_2 (MyDropout)    multiple                  0         \n",
      "                                                                 \n",
      " my_layer_6 (MyLayer)        multiple                  4160      \n",
      "                                                                 \n",
      " my_dropout_3 (MyDropout)    multiple                  0         \n",
      "                                                                 \n",
      " my_layer_7 (MyLayer)        multiple                  2990      \n",
      "                                                                 \n",
      " softmax_2 (Softmax)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model object\n",
    "\n",
    "model = MyModel(64, 64, 46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "565248/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "print(text_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 3.302, Accuracy: 47.996%\n",
      "Epoch 001: Loss: 1.920, Accuracy: 60.443%\n",
      "Epoch 002: Loss: 1.829, Accuracy: 65.030%\n",
      "Epoch 003: Loss: 1.782, Accuracy: 67.502%\n",
      "Epoch 004: Loss: 1.753, Accuracy: 68.147%\n",
      "Epoch 005: Loss: 1.744, Accuracy: 69.005%\n",
      "Epoch 006: Loss: 1.726, Accuracy: 69.595%\n",
      "Epoch 007: Loss: 1.723, Accuracy: 69.906%\n",
      "Epoch 008: Loss: 1.708, Accuracy: 70.107%\n",
      "Epoch 009: Loss: 1.716, Accuracy: 70.597%\n",
      "Duration :503.478\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# Keep results from plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_dataset:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # Compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        # Compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                               epoch_loss_avg.result(),\n",
    "                                                               epoch_accuracy.result()))\n",
    "\n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.813\n",
      "Test accuracy: 67.231%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "model = MyModel(64, 64, 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 2.442, Accuracy: 55.188%\n",
      "Epoch 001: Loss: 1.953, Accuracy: 63.805%\n",
      "Epoch 002: Loss: 1.850, Accuracy: 66.578%\n",
      "Epoch 003: Loss: 1.808, Accuracy: 67.902%\n",
      "Epoch 004: Loss: 1.772, Accuracy: 69.105%\n",
      "Epoch 005: Loss: 1.753, Accuracy: 69.071%\n",
      "Epoch 006: Loss: 1.757, Accuracy: 69.706%\n",
      "Epoch 007: Loss: 1.736, Accuracy: 69.895%\n",
      "Epoch 008: Loss: 1.719, Accuracy: 69.739%\n",
      "Epoch 009: Loss: 1.708, Accuracy: 70.274%\n",
      "Duration :351.228\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "# Keep results from plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    # Training loop\n",
    "    for x, y in train_dataset:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        # Compute current loss\n",
    "        epoch_loss_avg(loss_value)\n",
    "        # Compare predicted label to actual label\n",
    "        epoch_accuracy(to_categorical(y), model(x))\n",
    "        \n",
    "    # end epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                               epoch_loss_avg.result(),\n",
    "                                                               epoch_accuracy.result()))\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        with ag__.ld(tf).GradientTape() as tape:\n",
      "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
